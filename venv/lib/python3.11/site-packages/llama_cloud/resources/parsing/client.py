# This file was auto-generated by Fern from our API Definition.

import typing
import urllib.parse
from json.decoder import JSONDecodeError

from ...core.api_error import ApiError
from ...core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ...core.jsonable_encoder import jsonable_encoder
from ...core.remove_none_from_dict import remove_none_from_dict
from ...errors.unprocessable_entity_error import UnprocessableEntityError
from ...types.http_validation_error import HttpValidationError
from ...types.llama_parse_supported_file_extensions import LlamaParseSupportedFileExtensions
from ...types.parser_languages import ParserLanguages
from ...types.parsing_history_item import ParsingHistoryItem
from ...types.parsing_job import ParsingJob
from ...types.parsing_job_json_result import ParsingJobJsonResult
from ...types.parsing_job_markdown_result import ParsingJobMarkdownResult
from ...types.parsing_job_structured_result import ParsingJobStructuredResult
from ...types.parsing_job_text_result import ParsingJobTextResult
from ...types.parsing_usage import ParsingUsage
from ...types.presigned_url import PresignedUrl

try:
    import pydantic
    if pydantic.__version__.startswith("1."):
        raise ImportError
    import pydantic.v1 as pydantic  # type: ignore
except ImportError:
    import pydantic  # type: ignore

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class ParsingClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def get_job_image_result(self, job_id: str, name: str) -> typing.Iterator[bytes]:
        """
        Get a job by id

        Parameters:
            - job_id: str.

            - name: str.
        """
        with self._client_wrapper.httpx_client.stream(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/image/{name}"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        ) as _response:
            if 200 <= _response.status_code < 300:
                for _chunk in _response.iter_bytes():
                    yield _chunk
                return
            _response.read()
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    pydantic.parse_obj_as(HttpValidationError, _response.json())  # type: ignore
                )
            try:
                _response_json = _response.json()
            except JSONDecodeError:
                raise ApiError(status_code=_response.status_code, body=_response.text)
            raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_supported_file_extensions(self) -> typing.List[LlamaParseSupportedFileExtensions]:
        """
        Get a list of supported file extensions

        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.parsing.get_supported_file_extensions()
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/parsing/supported_file_extensions"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.List[LlamaParseSupportedFileExtensions], _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def upload_file(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        language: typing.Optional[typing.List[ParserLanguages]] = None,
        parsing_instruction: typing.Optional[str] = None,
        skip_diagonal_text: typing.Optional[bool] = None,
        invalidate_cache: typing.Optional[bool] = None,
        output_pdf_of_document: typing.Optional[bool] = None,
        do_not_cache: typing.Optional[bool] = None,
        gpt_4_o_mode: typing.Optional[bool] = None,
        fast_mode: typing.Optional[bool] = None,
        premium_mode: typing.Optional[bool] = None,
        continuous_mode: typing.Optional[bool] = None,
        gpt_4_o_api_key: typing.Optional[str] = None,
        do_not_unroll_columns: typing.Optional[bool] = None,
        html_make_all_elements_visible: typing.Optional[bool] = None,
        html_remove_fixed_elements: typing.Optional[bool] = None,
        guess_xlsx_sheet_name: typing.Optional[bool] = None,
        page_separator: typing.Optional[str] = None,
        bounding_box: typing.Optional[str] = None,
        bbox_top: typing.Optional[float] = None,
        bbox_right: typing.Optional[float] = None,
        bbox_bottom: typing.Optional[float] = None,
        bbox_left: typing.Optional[float] = None,
        target_pages: typing.Optional[str] = None,
        use_vendor_multimodal_model: typing.Optional[bool] = None,
        vendor_multimodal_model_name: typing.Optional[str] = None,
        vendor_multimodal_api_key: typing.Optional[str] = None,
        page_prefix: typing.Optional[str] = None,
        page_suffix: typing.Optional[str] = None,
        webhook_url: typing.Optional[str] = None,
        take_screenshot: typing.Optional[bool] = None,
        is_formatting_instruction: typing.Optional[bool] = None,
        disable_ocr: typing.Optional[bool] = None,
        annotate_links: typing.Optional[bool] = None,
        disable_reconstruction: typing.Optional[bool] = None,
        disable_image_extraction: typing.Optional[bool] = None,
        input_s_3_path: typing.Optional[str] = None,
        output_s_3_path_prefix: typing.Optional[str] = None,
        azure_openai_deployment_name: typing.Optional[str] = None,
        azure_openai_endpoint: typing.Optional[str] = None,
        azure_openai_api_version: typing.Optional[str] = None,
        azure_openai_key: typing.Optional[str] = None,
        auto_mode: typing.Optional[bool] = None,
        auto_mode_trigger_on_regexp_in_page: typing.Optional[str] = None,
        auto_mode_trigger_on_text_in_page: typing.Optional[str] = None,
        auto_mode_trigger_on_table_in_page: typing.Optional[bool] = None,
        auto_mode_trigger_on_image_in_page: typing.Optional[bool] = None,
        file: typing.Optional[str] = None,
        input_url: typing.Optional[str] = None,
        http_proxy: typing.Optional[str] = None,
        structured_output: typing.Optional[bool] = None,
        structured_output_json_schema: typing.Optional[str] = None,
        structured_output_json_schema_name: typing.Optional[str] = None,
        max_pages: typing.Optional[int] = None,
    ) -> ParsingJob:
        """
        Upload a file to s3 and create a job. return a job id

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - language: typing.Optional[typing.List[ParserLanguages]].

            - parsing_instruction: typing.Optional[str].

            - skip_diagonal_text: typing.Optional[bool].

            - invalidate_cache: typing.Optional[bool].

            - output_pdf_of_document: typing.Optional[bool].

            - do_not_cache: typing.Optional[bool].

            - gpt_4_o_mode: typing.Optional[bool].

            - fast_mode: typing.Optional[bool].

            - premium_mode: typing.Optional[bool].

            - continuous_mode: typing.Optional[bool].

            - gpt_4_o_api_key: typing.Optional[str].

            - do_not_unroll_columns: typing.Optional[bool].

            - html_make_all_elements_visible: typing.Optional[bool].

            - html_remove_fixed_elements: typing.Optional[bool].

            - guess_xlsx_sheet_name: typing.Optional[bool].

            - page_separator: typing.Optional[str].

            - bounding_box: typing.Optional[str].

            - bbox_top: typing.Optional[float].

            - bbox_right: typing.Optional[float].

            - bbox_bottom: typing.Optional[float].

            - bbox_left: typing.Optional[float].

            - target_pages: typing.Optional[str].

            - use_vendor_multimodal_model: typing.Optional[bool].

            - vendor_multimodal_model_name: typing.Optional[str].

            - vendor_multimodal_api_key: typing.Optional[str].

            - page_prefix: typing.Optional[str].

            - page_suffix: typing.Optional[str].

            - webhook_url: typing.Optional[str].

            - take_screenshot: typing.Optional[bool].

            - is_formatting_instruction: typing.Optional[bool].

            - disable_ocr: typing.Optional[bool].

            - annotate_links: typing.Optional[bool].

            - disable_reconstruction: typing.Optional[bool].

            - disable_image_extraction: typing.Optional[bool].

            - input_s_3_path: typing.Optional[str].

            - output_s_3_path_prefix: typing.Optional[str].

            - azure_openai_deployment_name: typing.Optional[str].

            - azure_openai_endpoint: typing.Optional[str].

            - azure_openai_api_version: typing.Optional[str].

            - azure_openai_key: typing.Optional[str].

            - auto_mode: typing.Optional[bool].

            - auto_mode_trigger_on_regexp_in_page: typing.Optional[str].

            - auto_mode_trigger_on_text_in_page: typing.Optional[str].

            - auto_mode_trigger_on_table_in_page: typing.Optional[bool].

            - auto_mode_trigger_on_image_in_page: typing.Optional[bool].

            - file: typing.Optional[str].

            - input_url: typing.Optional[str].

            - http_proxy: typing.Optional[str].

            - structured_output: typing.Optional[bool].

            - structured_output_json_schema: typing.Optional[str].

            - structured_output_json_schema_name: typing.Optional[str].

            - max_pages: typing.Optional[int].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.parsing.upload_file()
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/parsing/upload"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            data=jsonable_encoder(
                {
                    "language": language,
                    "parsing_instruction": parsing_instruction,
                    "skip_diagonal_text": skip_diagonal_text,
                    "invalidate_cache": invalidate_cache,
                    "output_pdf_of_document": output_pdf_of_document,
                    "do_not_cache": do_not_cache,
                    "gpt4o_mode": gpt_4_o_mode,
                    "fast_mode": fast_mode,
                    "premium_mode": premium_mode,
                    "continuous_mode": continuous_mode,
                    "gpt4o_api_key": gpt_4_o_api_key,
                    "do_not_unroll_columns": do_not_unroll_columns,
                    "html_make_all_elements_visible": html_make_all_elements_visible,
                    "html_remove_fixed_elements": html_remove_fixed_elements,
                    "guess_xlsx_sheet_name": guess_xlsx_sheet_name,
                    "page_separator": page_separator,
                    "bounding_box": bounding_box,
                    "bbox_top": bbox_top,
                    "bbox_right": bbox_right,
                    "bbox_bottom": bbox_bottom,
                    "bbox_left": bbox_left,
                    "target_pages": target_pages,
                    "use_vendor_multimodal_model": use_vendor_multimodal_model,
                    "vendor_multimodal_model_name": vendor_multimodal_model_name,
                    "vendor_multimodal_api_key": vendor_multimodal_api_key,
                    "page_prefix": page_prefix,
                    "page_suffix": page_suffix,
                    "webhook_url": webhook_url,
                    "take_screenshot": take_screenshot,
                    "is_formatting_instruction": is_formatting_instruction,
                    "disable_ocr": disable_ocr,
                    "annotate_links": annotate_links,
                    "disable_reconstruction": disable_reconstruction,
                    "disable_image_extraction": disable_image_extraction,
                    "input_s3_path": input_s_3_path,
                    "output_s3_path_prefix": output_s_3_path_prefix,
                    "azure_openai_deployment_name": azure_openai_deployment_name,
                    "azure_openai_endpoint": azure_openai_endpoint,
                    "azure_openai_api_version": azure_openai_api_version,
                    "azure_openai_key": azure_openai_key,
                    "auto_mode": auto_mode,
                    "auto_mode_trigger_on_regexp_in_page": auto_mode_trigger_on_regexp_in_page,
                    "auto_mode_trigger_on_text_in_page": auto_mode_trigger_on_text_in_page,
                    "auto_mode_trigger_on_table_in_page": auto_mode_trigger_on_table_in_page,
                    "auto_mode_trigger_on_image_in_page": auto_mode_trigger_on_image_in_page,
                    "file": file,
                    "input_url": input_url,
                    "http_proxy": http_proxy,
                    "structured_output": structured_output,
                    "structured_output_json_schema": structured_output_json_schema,
                    "structured_output_json_schema_name": structured_output_json_schema_name,
                    "max_pages": max_pages,
                }
            ),
            files={},
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def usage(self) -> ParsingUsage:
        """
        DEPRECATED: use either /organizations/{organization_id}/usage or /projects/{project_id}/usage instead
        Get parsing usage for user

        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.parsing.usage()
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/parsing/usage"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingUsage, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_job(self, job_id: str) -> ParsingJob:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.parsing.get_job(
            job_id="job_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_parsing_job_details(self, job_id: str) -> typing.Any:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.parsing.get_parsing_job_details(
            job_id="job_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/details"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Any, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_job_text_result(self, job_id: str) -> ParsingJobTextResult:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.parsing.get_job_text_result(
            job_id="job_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/text"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJobTextResult, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_job_raw_text_result(self, job_id: str) -> typing.Any:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.parsing.get_job_raw_text_result(
            job_id="job_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/raw/pdf"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Any, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_job_structured_result(self, job_id: str) -> ParsingJobStructuredResult:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.parsing.get_job_structured_result(
            job_id="job_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/structured"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJobStructuredResult, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_job_raw_structured_result(self, job_id: str) -> typing.Any:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.parsing.get_job_raw_structured_result(
            job_id="job_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/raw/structured"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Any, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_job_raw_xlsx_result(self, job_id: str) -> typing.Any:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.parsing.get_job_raw_xlsx_result(
            job_id="job_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/raw/xlsx"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Any, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_job_result(self, job_id: str) -> ParsingJobMarkdownResult:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.parsing.get_job_result(
            job_id="job_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/markdown"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJobMarkdownResult, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_job_raw_md_result(self, job_id: str) -> typing.Any:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.parsing.get_job_raw_md_result(
            job_id="job_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/raw/markdown"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Any, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_job_json_result(self, job_id: str) -> ParsingJobJsonResult:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.parsing.get_job_json_result(
            job_id="job_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/json"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJobJsonResult, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_job_json_raw_result(self, job_id: str) -> typing.Any:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.parsing.get_job_json_raw_result(
            job_id="job_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/raw/json"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Any, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_parsing_history_result(self) -> typing.List[ParsingHistoryItem]:
        """
        Get parsing history for user

        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.parsing.get_parsing_history_result()
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/parsing/history"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.List[ParsingHistoryItem], _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def generate_presigned_url(self, job_id: str, filename: str) -> PresignedUrl:
        """
        Generate a presigned URL for a job

        Parameters:
            - job_id: str.

            - filename: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.parsing.generate_presigned_url(
            job_id="job_id",
            filename="filename",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/read/{filename}"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PresignedUrl, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncParsingClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def get_job_image_result(self, job_id: str, name: str) -> typing.AsyncIterator[bytes]:
        """
        Get a job by id

        Parameters:
            - job_id: str.

            - name: str.
        """
        async with self._client_wrapper.httpx_client.stream(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/image/{name}"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        ) as _response:
            if 200 <= _response.status_code < 300:
                async for _chunk in _response.aiter_bytes():
                    yield _chunk
                return
            await _response.aread()
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    pydantic.parse_obj_as(HttpValidationError, _response.json())  # type: ignore
                )
            try:
                _response_json = _response.json()
            except JSONDecodeError:
                raise ApiError(status_code=_response.status_code, body=_response.text)
            raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_supported_file_extensions(self) -> typing.List[LlamaParseSupportedFileExtensions]:
        """
        Get a list of supported file extensions

        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.parsing.get_supported_file_extensions()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/parsing/supported_file_extensions"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.List[LlamaParseSupportedFileExtensions], _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def upload_file(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        language: typing.Optional[typing.List[ParserLanguages]] = None,
        parsing_instruction: typing.Optional[str] = None,
        skip_diagonal_text: typing.Optional[bool] = None,
        invalidate_cache: typing.Optional[bool] = None,
        output_pdf_of_document: typing.Optional[bool] = None,
        do_not_cache: typing.Optional[bool] = None,
        gpt_4_o_mode: typing.Optional[bool] = None,
        fast_mode: typing.Optional[bool] = None,
        premium_mode: typing.Optional[bool] = None,
        continuous_mode: typing.Optional[bool] = None,
        gpt_4_o_api_key: typing.Optional[str] = None,
        do_not_unroll_columns: typing.Optional[bool] = None,
        html_make_all_elements_visible: typing.Optional[bool] = None,
        html_remove_fixed_elements: typing.Optional[bool] = None,
        guess_xlsx_sheet_name: typing.Optional[bool] = None,
        page_separator: typing.Optional[str] = None,
        bounding_box: typing.Optional[str] = None,
        bbox_top: typing.Optional[float] = None,
        bbox_right: typing.Optional[float] = None,
        bbox_bottom: typing.Optional[float] = None,
        bbox_left: typing.Optional[float] = None,
        target_pages: typing.Optional[str] = None,
        use_vendor_multimodal_model: typing.Optional[bool] = None,
        vendor_multimodal_model_name: typing.Optional[str] = None,
        vendor_multimodal_api_key: typing.Optional[str] = None,
        page_prefix: typing.Optional[str] = None,
        page_suffix: typing.Optional[str] = None,
        webhook_url: typing.Optional[str] = None,
        take_screenshot: typing.Optional[bool] = None,
        is_formatting_instruction: typing.Optional[bool] = None,
        disable_ocr: typing.Optional[bool] = None,
        annotate_links: typing.Optional[bool] = None,
        disable_reconstruction: typing.Optional[bool] = None,
        disable_image_extraction: typing.Optional[bool] = None,
        input_s_3_path: typing.Optional[str] = None,
        output_s_3_path_prefix: typing.Optional[str] = None,
        azure_openai_deployment_name: typing.Optional[str] = None,
        azure_openai_endpoint: typing.Optional[str] = None,
        azure_openai_api_version: typing.Optional[str] = None,
        azure_openai_key: typing.Optional[str] = None,
        auto_mode: typing.Optional[bool] = None,
        auto_mode_trigger_on_regexp_in_page: typing.Optional[str] = None,
        auto_mode_trigger_on_text_in_page: typing.Optional[str] = None,
        auto_mode_trigger_on_table_in_page: typing.Optional[bool] = None,
        auto_mode_trigger_on_image_in_page: typing.Optional[bool] = None,
        file: typing.Optional[str] = None,
        input_url: typing.Optional[str] = None,
        http_proxy: typing.Optional[str] = None,
        structured_output: typing.Optional[bool] = None,
        structured_output_json_schema: typing.Optional[str] = None,
        structured_output_json_schema_name: typing.Optional[str] = None,
        max_pages: typing.Optional[int] = None,
    ) -> ParsingJob:
        """
        Upload a file to s3 and create a job. return a job id

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - language: typing.Optional[typing.List[ParserLanguages]].

            - parsing_instruction: typing.Optional[str].

            - skip_diagonal_text: typing.Optional[bool].

            - invalidate_cache: typing.Optional[bool].

            - output_pdf_of_document: typing.Optional[bool].

            - do_not_cache: typing.Optional[bool].

            - gpt_4_o_mode: typing.Optional[bool].

            - fast_mode: typing.Optional[bool].

            - premium_mode: typing.Optional[bool].

            - continuous_mode: typing.Optional[bool].

            - gpt_4_o_api_key: typing.Optional[str].

            - do_not_unroll_columns: typing.Optional[bool].

            - html_make_all_elements_visible: typing.Optional[bool].

            - html_remove_fixed_elements: typing.Optional[bool].

            - guess_xlsx_sheet_name: typing.Optional[bool].

            - page_separator: typing.Optional[str].

            - bounding_box: typing.Optional[str].

            - bbox_top: typing.Optional[float].

            - bbox_right: typing.Optional[float].

            - bbox_bottom: typing.Optional[float].

            - bbox_left: typing.Optional[float].

            - target_pages: typing.Optional[str].

            - use_vendor_multimodal_model: typing.Optional[bool].

            - vendor_multimodal_model_name: typing.Optional[str].

            - vendor_multimodal_api_key: typing.Optional[str].

            - page_prefix: typing.Optional[str].

            - page_suffix: typing.Optional[str].

            - webhook_url: typing.Optional[str].

            - take_screenshot: typing.Optional[bool].

            - is_formatting_instruction: typing.Optional[bool].

            - disable_ocr: typing.Optional[bool].

            - annotate_links: typing.Optional[bool].

            - disable_reconstruction: typing.Optional[bool].

            - disable_image_extraction: typing.Optional[bool].

            - input_s_3_path: typing.Optional[str].

            - output_s_3_path_prefix: typing.Optional[str].

            - azure_openai_deployment_name: typing.Optional[str].

            - azure_openai_endpoint: typing.Optional[str].

            - azure_openai_api_version: typing.Optional[str].

            - azure_openai_key: typing.Optional[str].

            - auto_mode: typing.Optional[bool].

            - auto_mode_trigger_on_regexp_in_page: typing.Optional[str].

            - auto_mode_trigger_on_text_in_page: typing.Optional[str].

            - auto_mode_trigger_on_table_in_page: typing.Optional[bool].

            - auto_mode_trigger_on_image_in_page: typing.Optional[bool].

            - file: typing.Optional[str].

            - input_url: typing.Optional[str].

            - http_proxy: typing.Optional[str].

            - structured_output: typing.Optional[bool].

            - structured_output_json_schema: typing.Optional[str].

            - structured_output_json_schema_name: typing.Optional[str].

            - max_pages: typing.Optional[int].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.parsing.upload_file()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/parsing/upload"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            data=jsonable_encoder(
                {
                    "language": language,
                    "parsing_instruction": parsing_instruction,
                    "skip_diagonal_text": skip_diagonal_text,
                    "invalidate_cache": invalidate_cache,
                    "output_pdf_of_document": output_pdf_of_document,
                    "do_not_cache": do_not_cache,
                    "gpt4o_mode": gpt_4_o_mode,
                    "fast_mode": fast_mode,
                    "premium_mode": premium_mode,
                    "continuous_mode": continuous_mode,
                    "gpt4o_api_key": gpt_4_o_api_key,
                    "do_not_unroll_columns": do_not_unroll_columns,
                    "html_make_all_elements_visible": html_make_all_elements_visible,
                    "html_remove_fixed_elements": html_remove_fixed_elements,
                    "guess_xlsx_sheet_name": guess_xlsx_sheet_name,
                    "page_separator": page_separator,
                    "bounding_box": bounding_box,
                    "bbox_top": bbox_top,
                    "bbox_right": bbox_right,
                    "bbox_bottom": bbox_bottom,
                    "bbox_left": bbox_left,
                    "target_pages": target_pages,
                    "use_vendor_multimodal_model": use_vendor_multimodal_model,
                    "vendor_multimodal_model_name": vendor_multimodal_model_name,
                    "vendor_multimodal_api_key": vendor_multimodal_api_key,
                    "page_prefix": page_prefix,
                    "page_suffix": page_suffix,
                    "webhook_url": webhook_url,
                    "take_screenshot": take_screenshot,
                    "is_formatting_instruction": is_formatting_instruction,
                    "disable_ocr": disable_ocr,
                    "annotate_links": annotate_links,
                    "disable_reconstruction": disable_reconstruction,
                    "disable_image_extraction": disable_image_extraction,
                    "input_s3_path": input_s_3_path,
                    "output_s3_path_prefix": output_s_3_path_prefix,
                    "azure_openai_deployment_name": azure_openai_deployment_name,
                    "azure_openai_endpoint": azure_openai_endpoint,
                    "azure_openai_api_version": azure_openai_api_version,
                    "azure_openai_key": azure_openai_key,
                    "auto_mode": auto_mode,
                    "auto_mode_trigger_on_regexp_in_page": auto_mode_trigger_on_regexp_in_page,
                    "auto_mode_trigger_on_text_in_page": auto_mode_trigger_on_text_in_page,
                    "auto_mode_trigger_on_table_in_page": auto_mode_trigger_on_table_in_page,
                    "auto_mode_trigger_on_image_in_page": auto_mode_trigger_on_image_in_page,
                    "file": file,
                    "input_url": input_url,
                    "http_proxy": http_proxy,
                    "structured_output": structured_output,
                    "structured_output_json_schema": structured_output_json_schema,
                    "structured_output_json_schema_name": structured_output_json_schema_name,
                    "max_pages": max_pages,
                }
            ),
            files={},
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def usage(self) -> ParsingUsage:
        """
        DEPRECATED: use either /organizations/{organization_id}/usage or /projects/{project_id}/usage instead
        Get parsing usage for user

        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.parsing.usage()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/parsing/usage"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingUsage, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_job(self, job_id: str) -> ParsingJob:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.parsing.get_job(
            job_id="job_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_parsing_job_details(self, job_id: str) -> typing.Any:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.parsing.get_parsing_job_details(
            job_id="job_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/details"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Any, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_job_text_result(self, job_id: str) -> ParsingJobTextResult:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.parsing.get_job_text_result(
            job_id="job_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/text"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJobTextResult, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_job_raw_text_result(self, job_id: str) -> typing.Any:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.parsing.get_job_raw_text_result(
            job_id="job_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/raw/pdf"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Any, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_job_structured_result(self, job_id: str) -> ParsingJobStructuredResult:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.parsing.get_job_structured_result(
            job_id="job_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/structured"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJobStructuredResult, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_job_raw_structured_result(self, job_id: str) -> typing.Any:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.parsing.get_job_raw_structured_result(
            job_id="job_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/raw/structured"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Any, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_job_raw_xlsx_result(self, job_id: str) -> typing.Any:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.parsing.get_job_raw_xlsx_result(
            job_id="job_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/raw/xlsx"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Any, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_job_result(self, job_id: str) -> ParsingJobMarkdownResult:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.parsing.get_job_result(
            job_id="job_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/markdown"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJobMarkdownResult, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_job_raw_md_result(self, job_id: str) -> typing.Any:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.parsing.get_job_raw_md_result(
            job_id="job_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/raw/markdown"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Any, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_job_json_result(self, job_id: str) -> ParsingJobJsonResult:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.parsing.get_job_json_result(
            job_id="job_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/json"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJobJsonResult, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_job_json_raw_result(self, job_id: str) -> typing.Any:
        """
        Get a job by id

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.parsing.get_job_json_raw_result(
            job_id="job_id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/result/raw/json"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Any, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_parsing_history_result(self) -> typing.List[ParsingHistoryItem]:
        """
        Get parsing history for user

        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.parsing.get_parsing_history_result()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/parsing/history"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.List[ParsingHistoryItem], _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def generate_presigned_url(self, job_id: str, filename: str) -> PresignedUrl:
        """
        Generate a presigned URL for a job

        Parameters:
            - job_id: str.

            - filename: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.parsing.generate_presigned_url(
            job_id="job_id",
            filename="filename",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/parsing/job/{job_id}/read/{filename}"
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PresignedUrl, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
